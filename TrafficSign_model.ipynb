{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtwHH92zlAke"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Dropout, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import load_model\n",
        "from numpy import loadtx\n",
        "print(\"finished importing\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "################# Parameters #####################\n",
        "path = \"myData\" # folder with all the class folders\n",
        "labelFile = 'labels.csv' # file with all names of classes\n",
        "batch_size_val = 50\n",
        "epochs_val = 30\n",
        "imageDimesions = (32, 32, 3)\n",
        "testRatio = 0.2\n",
        "validationRatio = 0.2\n"
      ],
      "metadata": {
        "id": "E2nGYQQZliAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###################################################\n",
        "############################### Importing of the Images\n",
        "count = 0\n",
        "images = []\n",
        "classNo = []\n",
        "myList = os.listdir(path)\n",
        "print(\"Total Classes Detected:\",len(myList))\n",
        "noOfClasses=len(myList)\n",
        "print(\"Importing Classes.....\")\n",
        "for x in range (0,len(myList)):\n",
        " myPicList = os.listdir(path+\"/\"+str(count))\n",
        "XV\n",
        " for y in myPicList:\n",
        " curImg = cv2.imread(path+\"/\"+str(count)+\"/\"+y)\n",
        " images.append(curImg)\n",
        " classNo.append(count)\n",
        " print(count, end =\" \")\n",
        " count +=1\n",
        "print(\" \")\n",
        "images = np.array(images)\n",
        "classNo = np.array(classNo)"
      ],
      "metadata": {
        "id": "olp8ULMAlpIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################### Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, classNo, test_size=testRatio)\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, \n",
        "test_size=validationRatio)\n",
        "steps_per_epoch_val = len(X_train) // batch_size_val\n",
        "# X_train = ARRAY OF IMAGES TO TRAIN\n",
        "# y_train = CORRESPONDING CLASS ID"
      ],
      "metadata": {
        "id": "SSAAaCVIluja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################### TO CHECK IF NUMBER OF IMAGES MATCHES \n",
        "TO NUMBER OF LABELS FOR EACH DATA SET\n",
        "print(\"Data Shapes\")\n",
        "print(\"Train\", end=\"\");\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(\"Validation\", end=\"\");\n",
        "print(X_validation.shape, y_validation.shape)\n",
        "print(\"Test\", end=\"\");\n",
        "print(X_test.shape, y_test.shape)\n",
        "assert (X_train.shape[0] == y_train.shape[\n",
        " 0]), \"The number of images in not equal to the number of lables in training set\"\n",
        "assert (X_validation.shape[0] == y_validation.shape[\n",
        " 0]), \"The number of images in not equal to the number of lables in validation set\"\n",
        "assert (X_test.shape[0] == y_test.shape[0]), \"The number of images in not equal to the \n",
        "number of lables in test set\"\n",
        "assert (X_train.shape[1:] == (imageDimesions)), \" The dimesions of the Training images are \n",
        "wrong \"\n",
        "assert (X_validation.shape[1:] == (imageDimesions)), \" The dimesionas of the Validation \n",
        "images are wrong \"\n",
        "assert (X_test.shape[1:] == (imageDimesions)), \" The dimesionas of the Test images are \n",
        "wrong\""
      ],
      "metadata": {
        "id": "is4SFghNly1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################### READ CSV FILE\n",
        "data = pd.read_csv(labelFile)\n",
        "print(\"data shape \", data.shape, type(data))\n"
      ],
      "metadata": {
        "id": "SuvEvxDNl31f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################### DISPLAY SOME SAMPLES IMAGES OF ALL \n",
        "THE CLASSES\n",
        "num_of_samples = []\n",
        "cols = 5\n",
        "num_classes = noOfClasses\n",
        "fig, axs = plt.subplots(nrows=num_classes, ncols=cols, figsize=(5, 300))\n",
        "fig.tight_layout()\n",
        "for i in range(cols):\n",
        " for j, row in data.iterrows():\n",
        " x_selected = X_train[y_train == j]\n",
        " axs[j][i].imshow(x_selected[random.randint(0, len(x_selected) - 1), :, :], \n",
        "cmap=plt.get_cmap(\"gray\"))\n",
        " axs[j][i].axis(\"off\")\n",
        " if i == 2:\n",
        " axs[j][i].set_title(str(j) + \"-\" + row[\"Name\"])\n",
        " num_of_samples.append(len(x_selected))\n"
      ],
      "metadata": {
        "id": "mg1sB7i9l7l9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################### DISPLAY A BAR CHART SHOWING NO OF \n",
        "SAMPLES FOR EACH CATEGORY\n",
        "print(num_of_samples)\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.bar(range(0, num_classes), num_of_samples)\n",
        "plt.title(\"Distribution of the training dataset\")\n",
        "plt.xlabel(\"Class number\")\n",
        "plt.ylabel(\"Number of images\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VhswklSHl_5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################### PREPROCESSING THE IMAGES\n",
        "def grayscale(img):\n",
        " img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        " return img\n",
        "def equalize(img):\n",
        " img = cv2.equalizeHist(img)\n",
        " return img\n",
        "def preprocessing(img):\n",
        " img = grayscale(img) # CONVERT TO GRAYSCALE\n",
        " img = equalize(img) # STANDARDIZE THE LIGHTING IN AN IMAGE\n",
        " img = img / 255 # TO NORMALIZE VALUES BETWEEN 0 AND 1 INSTEAD OF 0 \n",
        "TO 255\n",
        " return img\n",
        "X_train = np.array(list(map(preprocessing, X_train))) # TO IRETATE AND PREPROCESS \n",
        "ALL IMAGES\n",
        "X_validation = np.array(list(map(preprocessing, X_validation)))\n",
        "X_test = np.array(list(map(preprocessing, X_test)))\n",
        "cv2.imshow(\"GrayScale Images\",X_train[random.randint(0, len(X_train) - 1)]) # TO \n",
        "CHECK IF THE TRAINING IS DONE PROPERLY"
      ],
      "metadata": {
        "id": "WoQU2nAEmCXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################### ADD A DEPTH OF 1\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
        "XVII\n",
        "X_validation = X_validation.reshape(X_validation.shape[0], X_validation.shape[1], \n",
        "X_validation.shape[2], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
        "############################### AUGMENTATAION OF IMAGES TO MAKE IT \n",
        "MORE GENERIC\n",
        "dataGen = ImageDataGenerator(width_shift_range=0.1,\n",
        " # 0.1 = 10% IF MORE THAN 1 E.G 10 THEN IT REFFERS TO NO. \n",
        "OF PIXELS EG 10 PIXELS\n",
        " height_shift_range=0.1,\n",
        " zoom_range=0.2, # 0.2 MEANS CAN GO FROM 0.8 TO 1.2\n",
        " shear_range=0.1, # MAGNITUDE OF SHEAR ANGLE\n",
        " rotation_range=10) # DEGREES\n",
        "dataGen.fit(X_train)\n",
        "batches = dataGen.flow(X_train, y_train,\n",
        " batch_size=20) # REQUESTING DATA GENRATOR TO GENERATE \n",
        "IMAGES BATCH SIZE = NO. OF IMAGES CREAED EACH TIME ITS CALLED\n",
        "X_batch, y_batch = next(batches)\n",
        "# TO SHOW AGMENTED IMAGE SAMPLES\n",
        "fig, axs = plt.subplots(1, 15, figsize=(20, 5))\n",
        "fig.tight_layout()\n",
        "for i in range(15):\n",
        " axs[i].imshow(X_batch[i].reshape(imageDimesions[0], imageDimesions[1]))\n",
        " axs[i].axis('off')\n",
        "plt.show()\n",
        "y_train = to_categorical(y_train, noOfClasses)\n",
        "y_validation = to_categorical(y_validation, noOfClasses)\n",
        "y_test = to_categorical(y_test, noOfClasses)"
      ],
      "metadata": {
        "id": "JUCHYWh1mFcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################### CONVOLUTION NEURAL NETWORK MODEL\n",
        "def myModel():\n",
        " no_Of_Filters = 60\n",
        " size_of_Filter = (5, 5) # THIS IS THE KERNEL THAT MOVE AROUND THE IMAGE \n",
        "TO GET THE FEATURES.\n",
        " # THIS WOULD REMOVE 2 PIXELS FROM EACH BORDER WHEN USING 32 32 \n",
        "IMAGE\n",
        " size_of_Filter2 = (3, 3)\n",
        " size_of_pool = (2, 2) # SCALE DOWN ALL FEATURE MAP TO GERNALIZE MORE, \n",
        "TO REDUCE OVERFITTING\n",
        " no_Of_Nodes = 500 # NO. OF NODES IN HIDDEN LAYERS\n",
        " model = Sequential()\n",
        " model.add((Conv2D(no_Of_Filters, size_of_Filter, input_shape=(imageDimesions[0], \n",
        "imageDimesions[1], 1),\n",
        " activation='relu'))) # ADDING MORE CONVOLUTION LAYERS = LESS \n",
        "FEATURES BUT CAN CAUSE ACCURACY TO INCREASE\n",
        " model.add((Conv2D(no_Of_Filters, size_of_Filter, activation='relu')))\n",
        "\n",
        " model.add(MaxPooling2D(pool_size=size_of_pool)) # DOES NOT EFFECT THE DEPTH/NO OF FILTERS\n",
        " model.add((Conv2D(no_Of_Filters // 2, size_of_Filter2, activation='relu')))\n",
        " model.add((Conv2D(no_Of_Filters // 2, size_of_Filter2, activation='relu')))\n",
        " model.add(MaxPooling2D(pool_size=size_of_pool))\n",
        " model.add(Dropout(0.5))\n",
        " model.add(Flatten())\n",
        " model.add(Dense(no_Of_Nodes, activation='relu'))\n",
        " model.add(Dropout(0.5)) # INPUTS NODES TO DROP WITH EACH UPDATE 1 ALL \n",
        "0 NONE\n",
        " model.add(Dense(noOfClasses, activation='softmax')) # OUTPUT LAYER"
      ],
      "metadata": {
        "id": "e10Di3cTmOBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPILE MODEL\n",
        "model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "return model\n",
        "#training\n",
        "model = myModel()\n",
        "model.build(input_shape=(22271, 32, 32, 1))\n",
        "model.summary()\n",
        "history = model.fit(dataGen.flow(X_train, y_train, batch_size=batch_size_val), \n",
        "steps_per_epoch=steps_per_epoch_val,\n",
        " epochs=epochs_val, validation_data=(X_validation, y_validation), shuffle=1)\n",
        "############################### PLOT\n",
        "plt.figure(1)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['training','validation'])\n",
        "plt.title('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.figure(2)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['training','validation'])\n",
        "plt.title('Acurracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "score =model.evaluate(X_test,y_test,verbose=0)\n",
        "print('Test Score:',score[0])\n",
        "print('Test Accuracy:',score[1])\n",
        "# STORE THE MODEL AS An OBJECT\n",
        "model.save(\"modelfinal.h5\")"
      ],
      "metadata": {
        "id": "GUzuhc4pmSbY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}